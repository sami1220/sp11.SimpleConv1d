{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## 問題1 チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "forward : [35. 50.]\nbackward : (30, array([ 50.,  80., 110.]), array([ 30., 110., 170., 140.]))\n"
     ]
    }
   ],
   "source": [
    "class SimpleConv1d():\n",
    "    \"\"\"畳み込みクラス\"\"\"\n",
    "    def forward(self, x, w, b):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        # x : 入力配列\n",
    "        # w : 重み\n",
    "        # b : バイアス\n",
    "        a = np.empty((2, 3))\n",
    "        a[0] = x[0:-1]*w # x[indexes0]は([1, 2, 3])である\n",
    "        a[1] = x[1:]*w # x[indexes1]は([2, 3, 4])である\n",
    "        a = a.sum(axis=1)\n",
    "        return a + b\n",
    "    \n",
    "    def backward(self, x, w, da):\n",
    "        \"\"\"逆伝播\"\"\"\n",
    "        # x : 入力配列\n",
    "        # w : 重み\n",
    "        # da : 逆伝播の値\n",
    "        \n",
    "        # ---勾配---\n",
    "        # バイアスの分母\n",
    "        db = np.sum(da)\n",
    "\n",
    "        # 重みの分母\n",
    "        dw = np.zeros(len(w))\n",
    "        for i in range(len(w)):\n",
    "            dw[i] = da @ x[i:i+len(da)]\n",
    "        \n",
    "        # 逆畳込み計算用配列\n",
    "        new_w = np.insert(w[::-1], [0, 3], [0])\n",
    "\n",
    "        # 逆伝播した値\n",
    "        dx = np.zeros(len(new_w)-1)\n",
    "        for i in range(len(new_w)-1):\n",
    "            dx[i] = new_w[i:i+len(da)] @ da\n",
    "\n",
    "        return db, dw, dx[::-1]\n",
    "\n",
    "slc2 = SimpleConv1d()\n",
    "da = slc2.forward(x, w, b)\n",
    "\n",
    "print(f'forward : {slc2.forward(x, w, b)}')\n",
    "# print(f'backward : {slc2.backward(x, w, da)}')\n",
    "delta_a = np.array([10, 20])\n",
    "print(f'backward : {slc2.backward(x, w, delta_a)}')"
   ]
  },
  {
   "source": [
    "## 問題2 1次元畳み込み後の出力サイズの計算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "n_in = 2 #入力する特徴量の数 [:, 2]ってこと\n",
    "p = 2#パディングの数\n",
    "f = (3, 3)#フィルタのサイズタプルのどちらかの数字 (x, y)それぞれの出力に合わせて選択\n",
    "s = 3#ストライド\n",
    "\n",
    "def output_size_calculation(n_in, p, f, s):\n",
    "    \"\"\"出力サイズを計算 ゼロつく212p参照\"\"\"\n",
    "    n_out = int((n_in + (2 * p) - f) / s + 1)\n",
    "    #fにint型を渡すなら上の[1]を削除する\n",
    "    return n_out\n",
    "print(output_size_calculation(n_in, p, f[1], s))"
   ]
  },
  {
   "source": [
    "## 問題3 小さな配列での1次元畳み込み層の実験\n",
    "\n",
    "### 問題1で作ったクラスを実装してみる"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[35. 50.]\n30\n[ 50.  80. 110.]\n[ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "# テストデータ\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "da = np.array([10, 20])\n",
    "\n",
    "# クラスの確認\n",
    "slc = SimpleConv1d()\n",
    "print(slc.forward(x, w, b))#[35 50]\n",
    "print(slc.backward(x, w, da)[0])#(30, )\n",
    "print(slc.backward(x, w, da)[1])#[50, 80, 110]\n",
    "print(slc.backward(x, w, da)[2])#[30, 110, 170, 140]\n",
    "\n",
    "# backwardのreturn dx[::-1]をもう少し綺麗にかけないか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[35. 50.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "a = np.empty((2, 3))\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "\n",
    "a = a.sum(axis=1)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "forward : [35. 50.]\nbackward : (30, array([ 50.,  80., 110.]), array([ 30., 110., 170., 140.]))\n"
     ]
    }
   ],
   "source": [
    "print(f'forward : {slc2.forward(x, w, b)}')\n",
    "# print(f'backward : {slc2.backward(x, w, da)}')\n",
    "delta_a = np.array([10, 20])\n",
    "print(f'backward : {slc2.backward(x, w, delta_a)}')"
   ]
  },
  {
   "source": [
    "## 問題4 チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelFreeConv1d():\n",
    "    \"\"\"畳み込みクラス\"\"\"\n",
    "    def forward(self, x, w, b):\n",
    "        \"\"\"順伝播\"\"\"\n",
    "        # x : 入力配列\n",
    "        # w : 重み\n",
    "        # b : バイアス\n",
    "        a = np.empty((2, 3))\n",
    "        a[0] = x[0:-1]*w # x[indexes0]は([1, 2, 3])である\n",
    "        a[1] = x[1:]*w # x[indexes1]は([2, 3, 4])である\n",
    "        a = a.sum(axis=1)\n",
    "        return a + b\n",
    "    \n",
    "    def backward(self, x, w, da):\n",
    "        \"\"\"逆伝播\"\"\"\n",
    "        # x : 入力配列\n",
    "        # w : 重み\n",
    "        # da : 逆伝播の値\n",
    "        \n",
    "        # ---勾配---\n",
    "        # バイアスの分母\n",
    "        db = np.sum(da)\n",
    "\n",
    "        # 重みの分母\n",
    "        dw = np.zeros(len(w))\n",
    "        for i in range(len(w)):\n",
    "            dw[i] = da @ x[i:i+len(da)]\n",
    "        \n",
    "        # 逆畳込み計算用配列\n",
    "        new_w = np.insert(w[::-1], [0, 3], [0])\n",
    "\n",
    "        # 逆伝播した値\n",
    "        dx = np.zeros(len(new_w)-1)\n",
    "        for i in range(len(new_w)-1):\n",
    "            dx[i] = new_w[i:i+len(da)] @ da\n",
    "\n",
    "        return db, dw, dx[::-1]\n",
    "\n",
    "cfc = ChannelFreeConv1d()\n",
    "\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データ→行データに\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# onehotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 訓練データと評価データに\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "source": [
    "## 問題８"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def output_size_calculation(n_in, F, P=0, S=1):\n",
    "    \"\"\"出力サイズ計算\n",
    "    n_in : 入力サイズ\n",
    "    F : フィルターサイズ\n",
    "    P : パッディング数\n",
    "    S : ストライド数\n",
    "    \"\"\"\n",
    "    # 出力サイズの計算\n",
    "    n_out = int((n_in + 2*P - F) / S + 1)\n",
    "    \n",
    "    return n_out\n",
    "print(output_size_calculation(n_in=2, F=3, P=2, S=3))\n",
    "\n",
    "class Sigmoid:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return self.sigmoid(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        _sig = self.sigmoid(self.A)\n",
    "        return dZ * (1 - _sig)*_sig\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "class Tanh:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.tanh(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * (1 - (np.tanh(self.A))**2)\n",
    "\n",
    "class Softmax:\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, Y):\n",
    "        self.loss = self.loss_func(Y)\n",
    "        return self.Z - Y\n",
    "    \n",
    "    def loss_func(self, Y, Z=None):\n",
    "        if Z is None:\n",
    "            Z = self.Z\n",
    "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))\n",
    "\n",
    "class ReLU:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return np.clip(A, 0, None)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
    "\n",
    "class FC:\n",
    "\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        A = X@self.W + self.B\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dZ = dA@self.W.T\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.X.T@dA\n",
    "        self.optimizer.update(self)\n",
    "        return dZ\n",
    "\n",
    "class XavierInitializer:\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(1 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "    \n",
    "class HeInitializer():\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = math.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B\n",
    "\n",
    "class SGD:\n",
    "\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self, layer):\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return\n",
    "\n",
    "class AdaGrad:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "    \n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW**2\n",
    "        self.HB += layer.dB**2\n",
    "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
    "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
    "        \n",
    "class GetMiniBatch:\n",
    "\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1] \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "class SimpleInitializer:\n",
    "\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, *shape):\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    \n",
    "    def B(self, *shape):\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B\n",
    "    \n",
    "class AdaGrad:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "    \n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW**2\n",
    "        self.HB += layer.dB**2\n",
    "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
    "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
    "\n",
    "class Conv1d_Arbitrary_Strides:\n",
    "    \"\"\"畳み込みクラス\"\"\"\n",
    "    def __init__(self, b_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0, stride=1):\n",
    "        \"\"\"コンストラクタ\n",
    "        b_size : フィルターサイズ\n",
    "        initializer : 初期化クラス\n",
    "        optimizer : 最適化手法クラス\n",
    "        n_in_channels : 入力チャンネル数\n",
    "        n_out_channels : 出力チャンネル数\n",
    "        pa : パディング数\n",
    "        stride : ストライド数\n",
    "        \"\"\"\n",
    "        self.b_size = b_size\n",
    "        self.optimizer = optimizer\n",
    "        self.pa = pa\n",
    "        self.stride = stride\n",
    "        # 重みの初期化\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, b_size)\n",
    "        # バイアスの初期化\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"順伝播\n",
    "        X : 入力配列\n",
    "        \"\"\"\n",
    "        # バッチ数\n",
    "        self.n_samples = X.shape[0]\n",
    "        # 入力配列の特徴量数\n",
    "        self.n_in = X.shape[-1]\n",
    "        # 出力サイズ\n",
    "        self.n_out = output_size_calculation(self.n_in, self.b_size, self.pa, self.stride)\n",
    "        # 計算のためにX変形\n",
    "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in)\n",
    "        # 0埋め実施\n",
    "        self.X = np.pad(X, ((0,0), (0,0), ((self.b_size-1), 0)))\n",
    "        # 出力配列（A）の計算のためゼロ配列X1を用意する\n",
    "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.b_size, self.n_in+(self.b_size-1)))\n",
    "        # 重みの長さでループ\n",
    "        for i in range(self.b_size):\n",
    "            # ずらしながら上書き\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "        # 重みとバイアスを考慮して計算\n",
    "        A = np.sum(self.X1[:, np.newaxis, :, :, self.b_size-1-self.pa:self.n_in+self.pa:self.stride]*self.W[:, :, :, np.newaxis], axis=(2, 3)) + self.B.reshape(-1,1)\n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"逆伝播\n",
    "        dA : 逆伝播してきた配列\n",
    "        \"\"\"\n",
    "        # 重みの勾配\n",
    "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis]*self.X1[:, np.newaxis, :, :, self.b_size-1-self.pa:self.n_in+self.pa:self.stride], axis=(0, -1))\n",
    "        # バイアスの勾配\n",
    "        self.dB = np.sum(dA, axis=(0, -1))\n",
    "        # 逆伝播の値計算のためにdAを変形\n",
    "        self.dA = np.pad(dA, ((0,0), (0,0), (0, (self.b_size-1))))\n",
    "        # 出力配列（dX）の計算のためゼロ配列dA1を用意する\n",
    "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.b_size, self.dA.shape[-1]))\n",
    "        # 重みの長さでループ\n",
    "        for i in range(self.b_size):\n",
    "            self.dA1[:, :, i] = np.roll(self.dA, i, axis=-1)\n",
    "        dX = np.sum(self.W[:, :, :, np.newaxis]*self.dA1[:, :, np.newaxis], axis=(1,3))\n",
    "        # 重みとバイアスの更新\n",
    "        self.optimizer.update(self)\n",
    "        return dX\n",
    "class ScratchCNNClassifier:\n",
    "    \n",
    "    def __init__(self, num_epoch=10, lr=0.01, batch_size=20, n_features=784, n_nodes1=400, n_nodes2=200, n_output=10, verbose=True, Activater=Tanh, Optimizer=AdaGrad):\n",
    "        \"\"\"コンストラクタ\n",
    "        Parameters\n",
    "        -----------\n",
    "        num_epoch : 学習回数\n",
    "        lr : 学習率\n",
    "        batch_size : バッチサイズ\n",
    "        n_features : 特徴量数\n",
    "        n_nodes1 : 1層目のノード数\n",
    "        n_nodes2 : 2層目のノード数\n",
    "        n_output : 出力層の数\n",
    "        verbose : 仮定出力するか否か\n",
    "        Activater : 活性化関数\n",
    "        Optimizer : 最適化手法\n",
    "        \"\"\"\n",
    "        self.num_epoch = num_epoch\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose  \n",
    "        self.batch_size = batch_size \n",
    "        self.n_features = n_features \n",
    "        self.n_nodes2 = n_nodes2 \n",
    "        self.n_output = n_output \n",
    "        self.Activater = Activater\n",
    "        if Activater == Sigmoid or Activater == Tanh:\n",
    "            self.Initializer = XavierInitializer\n",
    "        elif Activater == ReLU:\n",
    "            self.Initializer = HeInitializer\n",
    "        self.Optimizer = Optimizer\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"学習\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y : 訓練データの目的変数\n",
    "        X_val : 評価データの説明変数\n",
    "        y_val : 評価データの目的変数\n",
    "        \"\"\"        \n",
    "        # レイヤー初期化\n",
    "        self.Conv1d_Arbitrary_Strides = Conv1d_Arbitrary_Strides(b_size=7, initializer=SimpleInitializer(0.01), optimizer=self.Optimizer(self.lr), n_in_channels=1, n_out_channels=1, pa=3, stride=2)\n",
    "        self.Conv1d_Arbitrary_Strides.n_out = output_size_calculation(X.shape[-1], self.Conv1d_Arbitrary_Strides.b_size, self.Conv1d_Arbitrary_Strides.pa, self.Conv1d_Arbitrary_Strides.stride)\n",
    "        self.activation1 = self.Activater()\n",
    "        self.FC2 = FC(1*self.Conv1d_Arbitrary_Strides.n_out, self.n_nodes2, self.Initializer(), self.Optimizer(self.lr))\n",
    "        self.activation2 = self.Activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.Initializer(), self.Optimizer(self.lr))\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        # loss配列定義と初期値格納（loss:ミニバッチごとの損失格納  loss_epoch:ミニバッチ学習終了後の全体損失）\n",
    "        self.loss = []\n",
    "        self.loss_epoch = [self.activation3.loss_func(y, self.forward_propagation(X))]\n",
    "        \n",
    "        # 学習回数分ループ\n",
    "        for _ in range(self.num_epoch):\n",
    "            # ミニバッチイテレータ生成\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "            # イテレータ呼び出し\n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                # 順伝播\n",
    "                self.forward_propagation(mini_X)\n",
    "                # 逆伝播\n",
    "                self.back_propagation(mini_X, mini_y)\n",
    "                # 損失記録\n",
    "                self.loss.append(self.activation3.loss)\n",
    "            # 損失記録\n",
    "            self.loss_epoch.append(self.activation3.loss_func(y, self.forward_propagation(X)))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測値出力\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 説明変数\n",
    "        \"\"\"\n",
    "        return np.argmax(self.forward_propagation(X), axis=1)\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        \"\"\"\n",
    "        A1 = self.Conv1d_Arbitrary_Strides.forward(X)\n",
    "        A1 = A1.reshape(A1.shape[0], A1.shape[-1])\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        return Z3\n",
    "        \n",
    "    def back_propagation(self, X, y_true):\n",
    "        \"\"\"逆伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 訓練データの説明変数\n",
    "        y_true : 正解データ\n",
    "        \"\"\"\n",
    "        dA3 = self.activation3.backward(y_true) \n",
    "        dZ2 = self.FC3.backward(dA3)\n",
    "        dA2 = self.activation2.backward(dZ2)\n",
    "        dZ1 = self.FC2.backward(dA2)\n",
    "        dA1 = self.activation1.backward(dZ1)\n",
    "        dA1 = dA1[:, np.newaxis]\n",
    "        dZ0 = self.Conv1d_Arbitrary_Strides.backward(dA1) \n",
    "\n",
    "# データ読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データ→行データに\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# onehotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "# 訓練データと評価データに\n",
    "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "cnn = ScratchCNNClassifier(num_epoch=20, lr=0.01, batch_size=20, n_features=784, n_nodes1=400, n_nodes2=400, n_output=10, verbose=True, Activater=Tanh, Optimizer=SGD)\n",
    "cnn.fit(X_train_[:1000], y_train_[:1000],X_test[:500],y_test[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 372.103125 263.63625\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 263.63625 \nL 372.103125 263.63625 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 239.758125 \nL 364.903125 239.758125 \nL 364.903125 22.318125 \nL 30.103125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m292a533af7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m292a533af7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.254968\" xlink:href=\"#m292a533af7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(96.711218 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.188629\" xlink:href=\"#m292a533af7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(157.644879 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.12229\" xlink:href=\"#m292a533af7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(218.57854 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"289.055951\" xlink:href=\"#m292a533af7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(279.512201 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"349.989611\" xlink:href=\"#m292a533af7\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(337.264611 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mfc05c3e0aa\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfc05c3e0aa\" y=\"229.993323\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 233.792541)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfc05c3e0aa\" y=\"188.243245\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 192.042464)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfc05c3e0aa\" y=\"146.493168\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 150.292387)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfc05c3e0aa\" y=\"104.743091\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 108.54231)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mfc05c3e0aa\" y=\"62.993014\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 66.792232)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p63401934ab)\" d=\"M 45.321307 35.732823 \nL 45.625975 37.772817 \nL 45.930643 37.920452 \nL 46.235312 39.789943 \nL 46.53998 32.201761 \nL 46.844648 39.600279 \nL 47.149317 36.437006 \nL 47.453985 42.791139 \nL 47.758653 45.483099 \nL 48.063322 35.510144 \nL 48.36799 49.093619 \nL 48.672658 55.184787 \nL 48.977326 75.543841 \nL 49.281995 65.388925 \nL 49.586663 110.606319 \nL 49.891331 84.547362 \nL 50.196 99.149437 \nL 50.500668 107.604912 \nL 50.805336 122.925559 \nL 51.110005 156.569013 \nL 51.414673 122.977152 \nL 52.02401 146.478702 \nL 52.328678 120.53391 \nL 52.633346 132.824167 \nL 52.938014 161.371954 \nL 53.242683 144.980649 \nL 53.547351 165.387199 \nL 53.852019 127.24756 \nL 54.156688 150.184741 \nL 54.461356 133.407035 \nL 54.766024 166.229624 \nL 55.070693 112.859222 \nL 55.375361 157.08941 \nL 55.984697 139.063376 \nL 56.289366 184.37639 \nL 56.594034 187.901799 \nL 56.898702 144.075126 \nL 57.203371 122.254079 \nL 57.508039 108.9854 \nL 57.812707 172.778762 \nL 58.117376 184.029463 \nL 58.422044 179.996809 \nL 58.726712 141.01677 \nL 59.031381 148.094784 \nL 59.336049 195.124076 \nL 59.640717 161.45999 \nL 59.945385 192.733027 \nL 60.250054 197.018214 \nL 60.554722 164.89298 \nL 61.164059 206.092165 \nL 61.468727 207.507821 \nL 61.773395 177.460215 \nL 62.078064 180.695722 \nL 62.382732 202.273248 \nL 62.6874 181.077032 \nL 62.992068 185.603663 \nL 63.296737 167.794422 \nL 63.601405 167.619699 \nL 63.906073 204.573805 \nL 64.210742 184.498654 \nL 64.51541 201.524247 \nL 64.820078 197.296793 \nL 65.124747 158.485367 \nL 65.429415 202.937813 \nL 65.734083 183.110558 \nL 66.038752 190.310456 \nL 66.34342 219.973369 \nL 66.648088 180.89371 \nL 66.952756 179.521474 \nL 67.257425 171.655189 \nL 67.562093 184.251377 \nL 67.866761 187.051304 \nL 68.17143 205.339762 \nL 68.476098 159.967857 \nL 68.780766 199.874445 \nL 69.085435 168.674525 \nL 69.390103 193.469031 \nL 69.694771 184.379409 \nL 69.999439 200.090125 \nL 70.304108 166.514251 \nL 70.608776 187.876564 \nL 70.913444 158.767357 \nL 71.218113 161.772402 \nL 71.827449 216.5009 \nL 72.132118 167.771647 \nL 72.436786 156.066742 \nL 72.741454 139.88805 \nL 73.046123 186.677228 \nL 73.350791 208.579818 \nL 73.655459 206.560177 \nL 73.960127 182.970104 \nL 74.264796 177.787494 \nL 74.569464 206.845518 \nL 74.874132 165.18865 \nL 75.178801 201.782802 \nL 75.483469 212.271711 \nL 75.788137 178.859096 \nL 76.092806 201.238047 \nL 76.397474 214.711122 \nL 76.702142 217.658956 \nL 77.006811 190.901625 \nL 77.311479 193.917069 \nL 77.616147 218.116157 \nL 77.920815 194.515349 \nL 78.225484 196.015484 \nL 78.530152 179.98615 \nL 78.83482 177.019521 \nL 79.139489 211.721962 \nL 79.444157 192.305306 \nL 79.748825 215.413143 \nL 80.053494 202.682268 \nL 80.358162 168.499944 \nL 80.66283 209.884833 \nL 80.967498 193.834405 \nL 81.272167 196.372801 \nL 81.576835 224.52472 \nL 81.881503 188.483506 \nL 82.186172 189.43346 \nL 82.49084 177.472952 \nL 82.795508 194.407021 \nL 83.100177 197.954239 \nL 83.404845 210.570384 \nL 83.709513 163.121325 \nL 84.014182 205.464349 \nL 84.31885 172.508289 \nL 84.623518 202.736604 \nL 84.928186 192.864238 \nL 85.232855 202.61331 \nL 85.537523 179.023963 \nL 85.842191 190.496687 \nL 86.14686 169.459684 \nL 86.451528 171.110577 \nL 86.756196 191.5214 \nL 87.060865 221.494209 \nL 87.365533 172.542238 \nL 87.670201 173.081475 \nL 87.974869 157.797444 \nL 88.584206 214.986524 \nL 88.888874 216.266386 \nL 89.498211 187.22812 \nL 89.802879 209.874649 \nL 90.107548 167.841423 \nL 90.412216 206.0079 \nL 90.716884 217.414712 \nL 91.021553 187.185763 \nL 91.326221 208.246637 \nL 91.630889 218.768925 \nL 91.935557 222.543206 \nL 92.240226 196.573975 \nL 92.544894 201.5148 \nL 92.849562 221.790655 \nL 93.154231 204.055603 \nL 93.458899 200.235352 \nL 93.763567 186.086516 \nL 94.068236 189.44331 \nL 94.372904 213.504097 \nL 94.677572 202.455981 \nL 94.98224 221.938873 \nL 95.286909 206.725866 \nL 95.591577 176.332121 \nL 95.896245 214.609462 \nL 96.200914 201.196502 \nL 96.505582 202.283988 \nL 96.81025 226.332516 \nL 97.114919 194.917433 \nL 97.419587 197.374194 \nL 97.724255 187.718101 \nL 98.028924 200.98565 \nL 98.333592 205.188997 \nL 98.63826 211.988931 \nL 98.942928 171.166865 \nL 99.247597 207.548479 \nL 99.552265 178.638658 \nL 99.856933 207.195031 \nL 100.161602 199.447967 \nL 100.46627 204.773231 \nL 100.770938 187.505921 \nL 101.075607 191.675699 \nL 101.380275 179.756408 \nL 101.684943 181.817652 \nL 101.989611 197.026908 \nL 102.29428 225.043087 \nL 102.598948 177.980568 \nL 102.903616 184.295521 \nL 103.208285 166.265523 \nL 103.817621 218.731274 \nL 104.12229 219.96741 \nL 104.426958 211.359476 \nL 104.731626 195.882696 \nL 105.036295 211.458705 \nL 105.340963 176.218225 \nL 105.645631 208.606893 \nL 105.950299 220.797912 \nL 106.254968 192.849935 \nL 106.559636 211.459154 \nL 106.864304 221.69357 \nL 107.168973 224.488558 \nL 107.473641 200.405737 \nL 107.778309 208.165607 \nL 108.082978 223.459361 \nL 108.387646 210.043006 \nL 108.692314 203.384716 \nL 108.996982 190.494703 \nL 109.301651 199.560826 \nL 109.606319 214.636937 \nL 109.910987 211.526227 \nL 110.215656 225.105851 \nL 110.520324 211.598528 \nL 110.824992 181.363357 \nL 111.129661 218.965144 \nL 111.434329 207.299504 \nL 111.738997 207.068516 \nL 112.043666 227.36665 \nL 112.348334 200.573192 \nL 112.653002 205.823458 \nL 112.95767 197.521308 \nL 113.262339 205.506161 \nL 113.871675 213.818781 \nL 114.176344 183.073601 \nL 114.481012 210.655775 \nL 114.78568 189.561111 \nL 115.090349 212.225214 \nL 115.395017 205.648599 \nL 115.699685 207.84267 \nL 116.004354 192.925716 \nL 116.309022 194.315279 \nL 116.61369 187.566456 \nL 116.918358 191.351023 \nL 117.223027 200.843915 \nL 117.527695 226.473832 \nL 117.832363 184.349418 \nL 118.137032 193.854973 \nL 118.4417 177.728739 \nL 119.051037 221.484982 \nL 119.355705 221.313618 \nL 119.660373 217.84303 \nL 119.965041 202.639892 \nL 120.26971 214.628578 \nL 120.574378 187.820768 \nL 120.879046 210.405964 \nL 121.183715 222.836485 \nL 121.488383 197.001296 \nL 121.793051 213.506919 \nL 122.09772 223.873022 \nL 122.402388 225.492564 \nL 122.707056 204.670885 \nL 123.316393 224.899587 \nL 124.230398 195.394577 \nL 124.839734 216.186618 \nL 125.144403 216.790429 \nL 125.449071 226.606845 \nL 125.753739 216.327364 \nL 126.058408 185.591789 \nL 126.363076 222.326496 \nL 126.667744 212.328177 \nL 126.972412 210.28875 \nL 127.277081 228.044052 \nL 127.581749 206.347638 \nL 127.886417 213.483106 \nL 128.191086 205.914322 \nL 128.800422 216.814238 \nL 129.105091 215.331692 \nL 129.409759 196.760809 \nL 129.714427 215.798525 \nL 130.019096 203.440922 \nL 130.323764 215.735273 \nL 130.628432 211.434184 \nL 130.9331 210.676282 \nL 131.237769 196.321173 \nL 131.542437 197.750688 \nL 131.847105 194.927647 \nL 132.456442 202.184671 \nL 132.76111 225.717604 \nL 133.065779 189.629006 \nL 133.370447 196.847394 \nL 133.675115 189.837617 \nL 133.979783 203.61788 \nL 134.284452 223.09296 \nL 134.58912 221.3503 \nL 134.893788 221.297715 \nL 135.198457 207.978423 \nL 135.503125 219.172593 \nL 135.807793 199.671261 \nL 136.41713 223.568981 \nL 136.721798 201.12695 \nL 137.331135 225.677024 \nL 137.635803 226.373941 \nL 137.940471 210.37903 \nL 138.24514 219.901899 \nL 138.549808 225.792046 \nL 138.854476 219.452613 \nL 139.463813 201.592136 \nL 139.768481 213.108631 \nL 140.07315 218.437241 \nL 140.377818 220.041405 \nL 140.682486 227.373912 \nL 140.987154 220.64198 \nL 141.291823 190.521872 \nL 141.596491 224.388968 \nL 141.901159 215.348093 \nL 142.205828 213.762934 \nL 142.510496 228.446434 \nL 142.815164 213.391068 \nL 143.119833 219.27643 \nL 143.424501 211.617295 \nL 144.033838 220.068267 \nL 144.338506 217.070649 \nL 144.643174 205.953092 \nL 144.947842 218.992386 \nL 145.252511 213.730629 \nL 145.557179 216.307372 \nL 146.166516 213.401115 \nL 146.471184 202.053266 \nL 146.775852 203.186247 \nL 147.080521 203.063729 \nL 147.385189 205.02602 \nL 147.689857 210.351167 \nL 147.994525 227.739257 \nL 148.299194 200.347121 \nL 148.603862 205.210404 \nL 148.90853 195.504292 \nL 149.213199 214.41763 \nL 149.517867 223.904716 \nL 149.822535 221.525995 \nL 150.127204 223.04614 \nL 150.431872 209.763041 \nL 150.73654 221.895577 \nL 151.041209 209.123782 \nL 151.345877 214.957781 \nL 151.650545 225.323488 \nL 151.955213 204.694925 \nL 152.56455 227.002932 \nL 152.869218 227.274086 \nL 153.173887 214.371045 \nL 153.478555 223.689923 \nL 153.783223 227.036598 \nL 154.087892 222.582188 \nL 154.39256 211.487987 \nL 154.697228 208.5933 \nL 155.001896 218.535422 \nL 155.611233 222.162807 \nL 155.915901 228.091203 \nL 156.22057 224.261969 \nL 156.525238 195.853097 \nL 156.829906 225.800828 \nL 157.134575 218.028875 \nL 157.439243 217.397418 \nL 157.743911 228.640303 \nL 158.04858 220.000581 \nL 158.353248 223.343018 \nL 158.657916 214.695607 \nL 159.267253 221.387861 \nL 159.571921 219.405124 \nL 159.876589 212.699471 \nL 160.181258 220.133459 \nL 160.485926 220.63068 \nL 160.790594 216.919711 \nL 161.095263 218.007011 \nL 161.399931 217.269668 \nL 161.704599 211.487249 \nL 162.009268 211.078371 \nL 162.313936 210.374372 \nL 162.618604 213.97559 \nL 162.923272 219.433986 \nL 163.227941 229.12292 \nL 163.532609 210.276335 \nL 163.837277 209.046222 \nL 164.141946 202.170285 \nL 164.446614 218.081439 \nL 164.751282 224.980842 \nL 165.055951 222.103497 \nL 165.360619 224.684403 \nL 165.665287 213.633639 \nL 165.969955 223.756757 \nL 166.274624 216.752499 \nL 166.579292 220.535397 \nL 166.88396 226.589769 \nL 167.188629 208.592196 \nL 167.797965 227.78471 \nL 168.102634 228.045357 \nL 168.407302 218.668099 \nL 168.71197 225.725715 \nL 169.016639 227.555099 \nL 169.321307 225.116211 \nL 169.625975 214.23968 \nL 169.930643 214.165177 \nL 170.235312 222.709164 \nL 170.53998 221.675457 \nL 170.844648 223.130449 \nL 171.149317 228.37714 \nL 171.453985 225.869441 \nL 171.758653 201.416962 \nL 172.063322 226.670382 \nL 172.36799 220.09912 \nL 172.672658 220.597558 \nL 172.977326 228.787059 \nL 173.281995 223.7532 \nL 173.586663 224.985497 \nL 173.891331 216.604324 \nL 174.196 220.277731 \nL 174.500668 221.897999 \nL 174.805336 221.452698 \nL 175.110005 217.850916 \nL 175.414673 220.054489 \nL 175.719341 223.479921 \nL 176.02401 219.000867 \nL 176.328678 220.902575 \nL 176.633346 220.892096 \nL 177.547351 215.683872 \nL 177.852019 216.819562 \nL 178.156688 225.653168 \nL 178.461356 229.388442 \nL 178.766024 213.288352 \nL 179.070693 213.978003 \nL 179.375361 205.453354 \nL 179.680029 224.022105 \nL 179.984697 226.580963 \nL 180.289366 225.607886 \nL 180.594034 226.847591 \nL 180.898702 218.649536 \nL 181.203371 225.672121 \nL 181.508039 221.320007 \nL 182.117376 227.215309 \nL 182.422044 215.855581 \nL 182.726712 220.284429 \nL 183.031381 228.12869 \nL 183.336049 228.65645 \nL 183.640717 223.464774 \nL 183.945385 224.658486 \nL 184.250054 227.79639 \nL 184.554722 227.149631 \nL 184.85939 216.532252 \nL 185.164059 218.865889 \nL 185.468727 224.26067 \nL 185.773395 223.357125 \nL 186.078064 223.70085 \nL 186.382732 228.460852 \nL 186.6874 226.658935 \nL 186.992068 208.332191 \nL 187.296737 227.332193 \nL 187.601405 221.397621 \nL 187.906073 222.519355 \nL 188.210742 228.950057 \nL 188.51541 226.054172 \nL 188.820078 225.157379 \nL 189.124747 220.201477 \nL 189.734083 222.892831 \nL 190.038752 223.666291 \nL 190.34342 222.079268 \nL 190.648088 218.778977 \nL 190.952756 223.757898 \nL 191.257425 222.545909 \nL 191.562093 223.226977 \nL 191.866761 224.346053 \nL 192.476098 221.209182 \nL 192.780766 218.570579 \nL 193.085435 213.765094 \nL 193.390103 225.899485 \nL 193.694771 229.13424 \nL 193.999439 215.972541 \nL 194.304108 215.844769 \nL 194.608776 209.039816 \nL 194.913444 224.949729 \nL 195.218113 226.702451 \nL 195.522781 224.129295 \nL 195.827449 226.64326 \nL 196.132118 218.981857 \nL 196.436786 225.916711 \nL 196.741454 222.04129 \nL 197.350791 227.763093 \nL 197.655459 220.15091 \nL 197.960127 221.046576 \nL 198.264796 228.311956 \nL 198.569464 229.063837 \nL 198.874132 224.766967 \nL 199.178801 225.533476 \nL 199.483469 228.69449 \nL 199.788137 227.930067 \nL 200.092806 217.319133 \nL 200.397474 223.211452 \nL 200.702142 225.664396 \nL 201.006811 224.03224 \nL 201.311479 224.750099 \nL 201.616147 228.647277 \nL 201.920815 227.607642 \nL 202.225484 214.182392 \nL 202.530152 227.518004 \nL 202.83482 223.511106 \nL 203.139489 224.698881 \nL 203.444157 229.146077 \nL 203.748825 226.989246 \nL 204.66283 223.611792 \nL 204.967498 223.260486 \nL 205.272167 225.960179 \nL 205.576835 224.83124 \nL 205.881503 218.153378 \nL 206.186172 225.37764 \nL 206.49084 222.539288 \nL 206.795508 225.198682 \nL 207.100177 226.379248 \nL 207.404845 224.004811 \nL 207.709513 222.576545 \nL 208.31885 219.181999 \nL 208.623518 226.360612 \nL 208.928186 229.629289 \nL 209.232855 222.094611 \nL 209.537523 218.775117 \nL 209.842191 208.803359 \nL 210.14686 224.624191 \nL 210.451528 228.383956 \nL 210.756196 223.402466 \nL 211.060865 226.15048 \nL 211.365533 222.622636 \nL 211.670201 226.241446 \nL 211.974869 224.366859 \nL 212.279538 227.164874 \nL 212.584206 228.497647 \nL 212.888874 224.017861 \nL 213.193543 222.788637 \nL 213.498211 227.684949 \nL 213.802879 229.378939 \nL 214.107548 225.090077 \nL 214.716884 229.430346 \nL 215.021553 228.066004 \nL 215.326221 220.662591 \nL 215.630889 225.168426 \nL 215.935557 225.773552 \nL 216.240226 224.725588 \nL 216.849562 228.72841 \nL 217.154231 228.27688 \nL 217.458899 220.06231 \nL 217.763567 227.866051 \nL 218.068236 225.086846 \nL 218.372904 225.565474 \nL 218.677572 229.309144 \nL 218.98224 227.626025 \nL 219.286909 226.952403 \nL 219.591577 225.82889 \nL 219.896245 225.152933 \nL 220.200914 224.97326 \nL 220.505582 226.116027 \nL 220.81025 226.409705 \nL 221.114919 220.678528 \nL 221.419587 227.065711 \nL 221.724255 222.128695 \nL 222.028924 226.31937 \nL 222.333592 227.366978 \nL 222.63826 224.878448 \nL 222.942928 224.166744 \nL 223.247597 221.844865 \nL 223.552265 223.156203 \nL 223.856933 225.771648 \nL 224.161602 229.797891 \nL 224.770938 221.283311 \nL 225.075607 203.770444 \nL 225.380275 219.153065 \nL 225.684943 228.740593 \nL 225.989611 217.076511 \nL 226.29428 211.087851 \nL 226.598948 170.54893 \nL 226.903616 159.992244 \nL 227.208285 170.407332 \nL 227.817621 220.853533 \nL 228.12229 210.274268 \nL 228.426958 220.210092 \nL 228.731626 224.450013 \nL 229.036295 227.069373 \nL 229.340963 220.871952 \nL 229.645631 228.014882 \nL 229.950299 229.273309 \nL 230.254968 228.348753 \nL 230.559636 216.859691 \nL 230.864304 224.040333 \nL 231.168973 223.000352 \nL 231.473641 226.230624 \nL 231.778309 225.017924 \nL 232.082978 228.966053 \nL 232.387646 228.933788 \nL 232.692314 213.609221 \nL 232.996982 226.959737 \nL 233.301651 223.88306 \nL 233.606319 223.383062 \nL 233.910987 229.399595 \nL 234.520324 226.676472 \nL 234.824992 224.049676 \nL 235.129661 222.933561 \nL 235.434329 227.098208 \nL 235.738997 226.38623 \nL 236.043666 224.505067 \nL 236.348334 224.508551 \nL 236.653002 227.404698 \nL 236.95767 223.96295 \nL 237.262339 224.76097 \nL 237.567007 227.901013 \nL 237.871675 224.273701 \nL 238.176344 226.04532 \nL 238.481012 220.25145 \nL 239.090349 226.136718 \nL 239.395017 229.756828 \nL 239.699685 226.411468 \nL 240.004354 220.175018 \nL 240.309022 199.013283 \nL 240.918358 228.968415 \nL 241.223027 219.827863 \nL 241.527695 225.683847 \nL 241.832363 222.432832 \nL 242.137032 227.333645 \nL 242.746368 228.953209 \nL 243.051037 227.095225 \nL 243.355705 217.68548 \nL 243.660373 220.683132 \nL 243.965041 227.341567 \nL 244.26971 229.297445 \nL 244.574378 225.133941 \nL 244.879046 228.151036 \nL 245.183715 229.581636 \nL 245.488383 228.123639 \nL 245.793051 223.165902 \nL 246.402388 226.243781 \nL 246.707056 225.858966 \nL 247.011725 226.472777 \nL 247.316393 228.922448 \nL 247.621061 228.773614 \nL 247.925729 223.016673 \nL 248.230398 228.064098 \nL 248.535066 225.137552 \nL 248.839734 226.467562 \nL 249.144403 229.283145 \nL 249.449071 227.765291 \nL 249.753739 227.892635 \nL 250.058408 224.463401 \nL 250.363076 226.395174 \nL 250.667744 226.554273 \nL 250.972412 228.028976 \nL 251.581749 225.986612 \nL 251.886417 227.778938 \nL 252.191086 225.918477 \nL 252.495754 225.217174 \nL 252.800422 228.251835 \nL 253.105091 225.056474 \nL 253.409759 226.330716 \nL 253.714427 223.385341 \nL 254.019096 224.879624 \nL 254.323764 220.7975 \nL 254.628432 229.731302 \nL 255.237769 221.643031 \nL 255.542437 213.098862 \nL 255.847105 227.928714 \nL 256.151774 227.776077 \nL 256.456442 229.037336 \nL 256.76111 228.471824 \nL 257.065779 226.422069 \nL 257.370447 225.35297 \nL 257.675115 225.599524 \nL 257.979783 229.14977 \nL 258.284452 228.46471 \nL 258.58912 224.819782 \nL 258.893788 227.134911 \nL 259.198457 222.449475 \nL 259.503125 229.552551 \nL 259.807793 224.035993 \nL 260.112462 229.239256 \nL 260.41713 229.504551 \nL 260.721798 228.72502 \nL 261.026467 223.740975 \nL 261.331135 227.166538 \nL 261.635803 225.425912 \nL 261.940471 227.455435 \nL 262.24514 227.853065 \nL 262.549808 228.961439 \nL 262.854476 229.011048 \nL 263.159145 226.607191 \nL 263.463813 228.3265 \nL 263.768481 226.696048 \nL 264.07315 227.085083 \nL 264.377818 229.242949 \nL 264.987154 227.531404 \nL 265.291823 226.132595 \nL 265.596491 226.30564 \nL 265.901159 227.53114 \nL 266.205828 227.984222 \nL 266.510496 227.982181 \nL 266.815164 227.173791 \nL 267.119833 228.383122 \nL 267.729169 226.055876 \nL 268.033838 228.422698 \nL 268.338506 226.265296 \nL 268.643174 226.738282 \nL 268.947842 226.042307 \nL 269.252511 224.860159 \nL 269.557179 226.572656 \nL 269.861847 229.692978 \nL 270.166516 227.579558 \nL 270.471184 226.392914 \nL 270.775852 223.703974 \nL 271.080521 227.422929 \nL 271.385189 225.579834 \nL 271.689857 229.368801 \nL 271.994525 229.000268 \nL 272.299194 227.383913 \nL 272.603862 227.352 \nL 272.90853 228.022773 \nL 273.213199 229.421455 \nL 273.517867 228.502477 \nL 273.822535 221.065888 \nL 274.431872 227.376383 \nL 274.73654 229.622709 \nL 275.041209 227.560383 \nL 275.345877 226.747809 \nL 275.650545 229.520491 \nL 275.955213 228.514086 \nL 276.259882 227.095647 \nL 276.56455 228.171462 \nL 276.869218 227.020154 \nL 277.173887 228.54561 \nL 277.478555 227.552565 \nL 277.783223 228.903852 \nL 278.087892 229.093016 \nL 278.39256 227.170145 \nL 278.697228 228.590384 \nL 279.001896 227.051121 \nL 279.306565 227.828364 \nL 279.611233 229.515724 \nL 279.915901 228.628536 \nL 280.22057 228.190275 \nL 280.525238 226.637354 \nL 280.829906 227.679897 \nL 281.134575 228.225689 \nL 281.439243 228.299214 \nL 281.743911 228.555754 \nL 282.04858 227.387303 \nL 282.353248 228.478982 \nL 282.657916 227.105086 \nL 282.962584 227.616872 \nL 283.267253 228.877249 \nL 283.571921 227.466747 \nL 283.876589 227.141813 \nL 284.485926 226.871895 \nL 284.790594 227.927652 \nL 285.095263 229.814851 \nL 285.399931 228.288627 \nL 285.704599 227.545194 \nL 286.009268 224.845181 \nL 286.313936 227.975883 \nL 286.618604 227.661531 \nL 286.923272 229.125624 \nL 287.227941 229.415391 \nL 287.532609 227.16426 \nL 287.837277 228.4694 \nL 288.141946 228.261637 \nL 288.446614 229.404165 \nL 288.751282 228.866631 \nL 289.055951 223.242584 \nL 289.360619 227.701016 \nL 289.665287 222.06037 \nL 289.969955 229.717946 \nL 290.274624 225.309355 \nL 290.579292 229.529355 \nL 290.88396 229.533237 \nL 291.188629 228.796612 \nL 291.493297 225.713636 \nL 291.797965 228.515327 \nL 292.102634 227.679513 \nL 292.71197 228.685481 \nL 293.321307 229.072598 \nL 293.625975 227.447405 \nL 293.930643 228.914189 \nL 294.235312 227.341954 \nL 294.844648 229.511791 \nL 295.149317 228.740313 \nL 295.453985 228.614213 \nL 295.758653 227.483317 \nL 296.063322 227.740576 \nL 296.36799 228.583362 \nL 296.977326 228.68114 \nL 297.281995 228.176764 \nL 297.586663 228.700484 \nL 297.891331 228.171375 \nL 298.196 227.114038 \nL 298.500668 229.008541 \nL 298.805336 227.912176 \nL 299.110005 227.659157 \nL 299.414673 227.552446 \nL 299.719341 227.297736 \nL 300.328678 229.822921 \nL 300.633346 228.467732 \nL 300.938014 227.89447 \nL 301.242683 226.021167 \nL 301.547351 228.666347 \nL 301.852019 228.151495 \nL 302.461356 229.520137 \nL 302.766024 227.167499 \nL 303.070693 228.634827 \nL 303.375361 228.432581 \nL 303.680029 229.414726 \nL 303.984697 229.06878 \nL 304.289366 224.098662 \nL 304.594034 228.37323 \nL 304.898702 223.049549 \nL 305.203371 229.756005 \nL 305.508039 226.834589 \nL 305.812707 229.183495 \nL 306.117376 229.58549 \nL 306.422044 229.000937 \nL 306.726712 226.622652 \nL 307.031381 228.919035 \nL 307.336049 228.261189 \nL 307.640717 228.676124 \nL 308.250054 229.056768 \nL 308.554722 229.119874 \nL 308.85939 227.668228 \nL 309.164059 229.087015 \nL 309.468727 227.708517 \nL 310.078064 229.640812 \nL 310.382732 228.905515 \nL 310.6874 228.823038 \nL 310.992068 228.200272 \nL 311.296737 227.950138 \nL 311.601405 228.89728 \nL 312.51541 228.529925 \nL 312.820078 228.85876 \nL 313.429415 227.956882 \nL 313.734083 229.095264 \nL 314.038752 228.45224 \nL 314.34342 228.084107 \nL 314.648088 228.072568 \nL 314.952756 227.790551 \nL 315.562093 229.842245 \nL 315.866761 228.602653 \nL 316.17143 228.212745 \nL 316.476098 226.696767 \nL 316.780766 228.879217 \nL 317.085435 228.556291 \nL 317.390103 228.809201 \nL 317.694771 229.586983 \nL 317.999439 227.458488 \nL 318.304108 228.684501 \nL 318.608776 228.512326 \nL 318.913444 229.421204 \nL 319.218113 229.210839 \nL 319.522781 225.016467 \nL 319.827449 228.871015 \nL 320.132118 224.712289 \nL 320.436786 229.762749 \nL 320.741454 228.276934 \nL 321.046123 228.115406 \nL 321.350791 229.67458 \nL 321.960127 227.936652 \nL 322.264796 229.205594 \nL 322.569464 228.589906 \nL 322.874132 229.095975 \nL 323.178801 228.919933 \nL 323.483469 229.001167 \nL 323.788137 229.227955 \nL 324.092806 227.979145 \nL 324.397474 229.198459 \nL 324.702142 228.075728 \nL 325.311479 229.685272 \nL 325.616147 229.06082 \nL 325.920815 228.973731 \nL 326.530152 228.340746 \nL 326.83482 229.108698 \nL 327.444157 228.807089 \nL 327.748825 228.65346 \nL 328.053494 228.960307 \nL 328.66283 228.338431 \nL 328.967498 229.192267 \nL 329.576835 228.24662 \nL 329.881503 228.363167 \nL 330.186172 228.205659 \nL 330.49084 228.894805 \nL 330.795508 229.865678 \nL 331.100177 228.733107 \nL 331.404845 228.467234 \nL 331.709513 227.131915 \nL 332.014182 229.088697 \nL 332.623518 228.742935 \nL 332.928186 229.641396 \nL 333.232855 227.780682 \nL 333.537523 228.699628 \nL 333.842191 228.468002 \nL 334.14686 229.434922 \nL 334.451528 229.310263 \nL 334.756196 225.723825 \nL 335.060865 229.136553 \nL 335.365533 226.820304 \nL 335.670201 229.725413 \nL 336.279538 228.65822 \nL 336.584206 229.711503 \nL 336.888874 229.223804 \nL 337.193543 228.31453 \nL 337.498211 229.308964 \nL 337.802879 228.885736 \nL 338.107548 229.235604 \nL 338.412216 229.042887 \nL 339.021553 229.346939 \nL 339.326221 228.219997 \nL 339.630889 229.263568 \nL 339.935557 228.325256 \nL 340.544894 229.729531 \nL 340.849562 229.173218 \nL 341.154231 229.121939 \nL 341.763567 228.552669 \nL 342.068236 229.22882 \nL 342.372904 229.171215 \nL 342.677572 228.947625 \nL 342.98224 228.911184 \nL 343.286909 229.055136 \nL 343.591577 228.849175 \nL 343.896245 228.77753 \nL 344.200914 229.208695 \nL 344.505582 228.977722 \nL 344.81025 228.56288 \nL 345.114919 228.627504 \nL 345.419587 228.475326 \nL 345.724255 229.054524 \nL 346.028924 229.874489 \nL 346.333592 228.856498 \nL 346.63826 228.628855 \nL 346.942928 227.490582 \nL 347.247597 229.18827 \nL 347.552265 229.124812 \nL 347.856933 228.774008 \nL 348.161602 229.670811 \nL 348.46627 228.0307 \nL 348.770938 228.821456 \nL 349.075607 228.737623 \nL 349.380275 229.451249 \nL 349.684943 229.369714 \nL 349.684943 229.369714 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 239.758125 \nL 30.103125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 239.758125 \nL 364.903125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 239.758125 \nL 364.903125 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 22.318125 \nL 364.903125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_12\">\n    <!-- SGD_loss -->\n    <defs>\n     <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n     <path d=\"M 59.515625 10.40625 \nL 59.515625 29.984375 \nL 43.40625 29.984375 \nL 43.40625 38.09375 \nL 69.28125 38.09375 \nL 69.28125 6.78125 \nQ 63.578125 2.734375 56.6875 0.65625 \nQ 49.8125 -1.421875 42 -1.421875 \nQ 24.90625 -1.421875 15.25 8.5625 \nQ 5.609375 18.5625 5.609375 36.375 \nQ 5.609375 54.25 15.25 64.234375 \nQ 24.90625 74.21875 42 74.21875 \nQ 49.125 74.21875 55.546875 72.453125 \nQ 61.96875 70.703125 67.390625 67.28125 \nL 67.390625 56.78125 \nQ 61.921875 61.421875 55.765625 63.765625 \nQ 49.609375 66.109375 42.828125 66.109375 \nQ 29.4375 66.109375 22.71875 58.640625 \nQ 16.015625 51.171875 16.015625 36.375 \nQ 16.015625 21.625 22.71875 14.15625 \nQ 29.4375 6.6875 42.828125 6.6875 \nQ 48.046875 6.6875 52.140625 7.59375 \nQ 56.25 8.5 59.515625 10.40625 \nz\n\" id=\"DejaVuSans-71\"/>\n     <path d=\"M 19.671875 64.796875 \nL 19.671875 8.109375 \nL 31.59375 8.109375 \nQ 46.6875 8.109375 53.6875 14.9375 \nQ 60.6875 21.78125 60.6875 36.53125 \nQ 60.6875 51.171875 53.6875 57.984375 \nQ 46.6875 64.796875 31.59375 64.796875 \nz\nM 9.8125 72.90625 \nL 30.078125 72.90625 \nQ 51.265625 72.90625 61.171875 64.09375 \nQ 71.09375 55.28125 71.09375 36.53125 \nQ 71.09375 17.671875 61.125 8.828125 \nQ 51.171875 0 30.078125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-68\"/>\n     <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n    </defs>\n    <g transform=\"translate(169.835625 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"63.476562\" xlink:href=\"#DejaVuSans-71\"/>\n     <use x=\"140.966797\" xlink:href=\"#DejaVuSans-68\"/>\n     <use x=\"217.96875\" xlink:href=\"#DejaVuSans-95\"/>\n     <use x=\"267.96875\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"295.751953\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"356.933594\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"409.033203\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p63401934ab\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "plt.title('SGD_loss')\n",
    "plt.plot(cnn.loss, label='loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}